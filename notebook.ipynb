{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62958446",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4340e3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple, Optional, Union\n",
    "from functools import reduce \n",
    "from pyntcloud import PyntCloud\n",
    "from tqdm import tqdm\n",
    "from matplotlib import rc\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 6)\n",
    "# rc('font', **{'family': 'serif', 'serif': ['Computer Modern'], 'size': 18})\n",
    "# rc('text', usetex=True)\n",
    "# rc('text.latex',preamble='\\\\usepackage[utf8]{inputenc}')\n",
    "# rc('text.latex',preamble='\\\\usepackage[russian]{babel}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52acbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLOR_BLUE = '#2CBDFE'\n",
    "COLOR_GREEN = '#47DBCD'\n",
    "COLOR_PINK = '#F3A0F2'\n",
    "COLOR_PURPLE = '#9D2EC5'\n",
    "COLOR_VIOLET = '#661D98'\n",
    "COLOR_AMBER = '#F5B14C'\n",
    "\n",
    "COLORS = [COLOR_PURPLE, COLOR_AMBER, COLOR_GREEN, COLOR_PINK, COLOR_VIOLET, COLOR_BLUE]\n",
    "def get_color(idx: int):\n",
    "    return COLORS[idx % len(COLORS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b348a5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_bar_plots(hists: np.ndarray, \n",
    "                   tick_labels: Optional[List[str]] = None,\n",
    "                   legend_labels: Optional[List[str]] = None,\n",
    "                   empty: float = 0.0,\n",
    "                   ticks_rotation: str = 'horizontal',\n",
    "                   ylabel: Optional[str] = None,\n",
    "                   xlabel: Optional[str] = None,\n",
    "                   horizontal=False):\n",
    "    if len(hists.shape) == 2:\n",
    "        n, m = hists.shape\n",
    "        x = np.arange(m)\n",
    "        f, ax = plt.subplots(figsize=(25, 5))\n",
    "        for i, y in enumerate(hists):\n",
    "            width = (1 - empty) / n\n",
    "            shift = (i + 0.5) * width - 0.5\n",
    "            if not horizontal:\n",
    "                ax.bar(x + shift, y, width=width, align='center', \n",
    "                       tick_label=tick_labels if i == len(hists) // 2 else None, label=legend_labels[i], color=get_color(i))\n",
    "            else:\n",
    "                ax.barh(x + shift, y, height=width, align='center', \n",
    "                        tick_label=tick_labels if i == len(hists) // 2 else None, label=legend_labels[i], color=get_color(i))\n",
    "    else:\n",
    "        l, n, m = hists.shape\n",
    "        x = np.arange(m)\n",
    "        f, ax = plt.subplots(figsize=(40, 16) if horizontal else (20, 4))\n",
    "        for j in range(l):\n",
    "            for i, y in enumerate(hists[j]):\n",
    "                width = (1 - empty) / n\n",
    "                shift = (i + 0.5) * width - 0.5\n",
    "                if not horizontal:\n",
    "                    ax.bar(x + shift, y, width=width, align='center', \n",
    "                           tick_label=tick_labels if i == len(hists) // 2 else None, label=legend_labels[i], color=get_color(j * n + i))\n",
    "                else:\n",
    "                    ax.barh(x + shift, y, height=width, align='center', \n",
    "                            tick_label=tick_labels if i == len(hists) // 2 else None, label=legend_labels[i], color=get_color(j * n + i))\n",
    "    plt.xticks(rotation=ticks_rotation)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.legend(loc='upper left') \n",
    "    ax.set_axisbelow(True)\n",
    "    ax.yaxis.grid(linestyle = '--', linewidth = 0.5) # horizontal lines \n",
    "    # plt.savefig(f'{ylabel}.png', bbox_inches='tight', dpi=200)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_line_graph(df, parameter_x, parameter_y, versions, descriptors=['fpfh', 'rops', 'shot']):\n",
    "    for v in versions:\n",
    "        for d in descriptors:\n",
    "            df_local = df[(df['version'] == v) & (df['descriptor'] == d)]\n",
    "            plt.plot(df_local[parameter_x].values, df_local[parameter_y].values, label=d + f' ({v})')\n",
    "            plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7b1c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_distances(path, thr=1.5, k=0):\n",
    "    df = pd.read_csv(path)\n",
    "    dists = np.sort(df.values.flatten())[-k:]\n",
    "    print('Number of good correspondences:', np.count_nonzero(dists < thr))\n",
    "    plt.fill_between(np.arange(len(dists)), np.zeros_like(dists), dists, facecolor='blue', alpha=0.5)\n",
    "    plt.hlines(thr, 0, len(dists) - 1, color='r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6367c04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_uniquenesses(path, a_max=300):\n",
    "    df = pd.read_csv(path)\n",
    "    dists = df.values.flatten()\n",
    "    dists = np.clip(np.sort(dists), a_min=0, a_max=a_max)\n",
    "    plt.hist(dists, bins='fd')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b46d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_confusion_matrix(hists1, hists2):\n",
    "    xx, yy = np.meshgrid(np.arange(len(hists1)), np.arange(len(hists2)))\n",
    "    return np.abs(np.stack((hists1[xx], hists2[yy]), axis=3).min(axis=3)).sum(axis=2)\n",
    "\n",
    "def l2_confusion_matrix(hists1, hists2):\n",
    "    xx, yy = np.meshgrid(np.arange(len(hists1)), np.arange(len(hists2)))\n",
    "    return np.sqrt(((hists1[xx] - hists2[yy]) ** 2).sum(axis=2))\n",
    "    \n",
    "def cosine_confusion_matrix(hists1, hists2):\n",
    "    xx, yy = np.meshgrid(np.arange(len(hists1)), np.arange(len(hists2)))\n",
    "    return np.sqrt((hists1[xx] * hists2[yy]).sum(axis=2))\n",
    "    \n",
    "def show_confusion_matrix(confusion_matrix, labels1=None, labels2=None, vmin=None, vmax=None):\n",
    "    res = plt.imshow(confusion_matrix, cmap=plt.cm.jet, vmin=vmin, vmax=vmax, interpolation='nearest')\n",
    "    plt.colorbar(res)\n",
    "   \n",
    "    if labels1 is not None: \n",
    "        plt.tick_params(labelbottom=False,labeltop=True)\n",
    "        plt.xticks(range(len(labels1)), labels1, rotation='vertical')\n",
    "    if labels2 is not None:\n",
    "        plt.yticks(range(len(labels2)), labels2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a8b11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skip_zeros(hist1, hist2):\n",
    "    mask = ~np.logical_and(hist1 == 0, hist2 == 0)\n",
    "    return hist1[mask], hist2[mask]\n",
    "\n",
    "def analyze_descriptors(path_src, path_tgt, ids_src, ids_tgt, descriptor_size, confusion_matrix_fn, descriptions=[], vmin=None, vmax=None):\n",
    "    hists_src = pd.read_csv(path_src, header=None, usecols=np.arange(descriptor_size).tolist())\n",
    "    hists_tgt = pd.read_csv(path_tgt, header=None, usecols=np.arange(descriptor_size).tolist())\n",
    "    for id_src, id_tgt in zip(ids_src, ids_tgt):\n",
    "        show_bar_plots(np.vstack((hists_src.iloc[id_src].values, hists_tgt.iloc[id_tgt].values)))\n",
    "   \n",
    "    show_confusion_matrix(confusion_matrix_fn(hists_src.iloc[ids_src].values, hists_tgt.iloc[ids_tgt].values),\n",
    "                          descriptions,\n",
    "                          descriptions,\n",
    "                          vmin=vmin, vmax=vmax) \n",
    "    show_confusion_matrix(confusion_matrix_fn(hists_src.iloc[ids_src].values, hists_src.iloc[ids_src].values),\n",
    "                          descriptions,\n",
    "                          descriptions,\n",
    "                          vmin=vmin, vmax=vmax) \n",
    "    show_confusion_matrix(confusion_matrix_fn(hists_tgt.iloc[ids_tgt].values, hists_tgt.iloc[ids_tgt].values),\n",
    "                          descriptions,\n",
    "                          descriptions,\n",
    "                          vmin=vmin, vmax=vmax) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bb812e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_uniquenesses('data/debug/KilwaKisiwani_40r_KilwaKisiwani_43r_uniquenesses_src_random_01.csv')\n",
    "# show_uniquenesses('data/debug/Hokuyo_4_Hokuyo_8_uniquenesses_src_random_01.csv')\n",
    "# show_uniquenesses('data/debug/bun000_bun045_uniquenesses_src_random_01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69d00e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "def display_colored(df, columns=[], cmap='PuBu', qmin=0.2, qmax=0.8):\n",
    "    filtered_columns =  list(filter(lambda c: c in df.columns and is_numeric_dtype(df[c]), columns))\n",
    "    styler = df.style\n",
    "    for column in filtered_columns:\n",
    "        styler.background_gradient(subset=[column], cmap=cmap, vmin=df[column].quantile(qmin), vmax=df[column].quantile(qmax))\n",
    "    display(styler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdb0e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('data/debug/test_metrics.csv')\n",
    "# df = df[['testname', 'metric_corr', 'metric_corr_gt', 'metric_icp', 'metric_icp_gt']]\n",
    "# df['combination'] = df['metric_corr'] * df['metric_icp']\n",
    "# df['combination_gt'] = df['metric_corr_gt'] * df['metric_icp_gt']\n",
    "# df['testname'] = df.testname.apply(lambda s: s[5:7] + '-' + s[16:18])\n",
    "# display(df.style.background_gradient(subset=['metric_corr', 'metric_icp', 'metric_corr_gt', 'metric_icp_gt', 'combination', 'combination_gt']))\n",
    "# latex_table = df.to_latex(float_format=\"%.3f\", index=False)\n",
    "# print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fb0d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['version', 'descriptor','testname', 'use_normals', 'rmse','r_err','t_err','pcd_err', 'normal_diff','voxel_size','normal_radius_coef','feature_radius_coef','pcc', 'correct_correspondences', 'correspondences', 'inliers', 'correct_inliers','filter','threshold','n_random', 'corr_uniformity', 'overlap_rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408f1abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('data/debug/test_results.csv')\n",
    "# df['pcc'] = df['correct_correspondences'] / df['correspondences']\n",
    "# display_colored(df, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df1f3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_lrfs(df, parameters, descriptors=['shot', 'rops'], lrf_types=['default', 'gt', 'gravity'], ticks_rotation='horizontal'):\n",
    "    for desc in descriptors:\n",
    "        df_desc = df[df['descriptor'] == desc]\n",
    "        testnames = list(sorted(reduce(np.intersect1d, [df_desc[df_desc['lrf'] == lrf]['testname'].values for lrf in lrf_types])))\n",
    "        df_desc = df_desc[df_desc['testname'].isin(testnames)]\n",
    "        df_desc = df_desc.sort_values('testname')\n",
    "        n, m = len(lrf_types), len(testnames)\n",
    "        if m == 0:\n",
    "            continue\n",
    "        for p in parameters:\n",
    "            hists = np.zeros((n, m))\n",
    "            tick_labels = []\n",
    "            for i, lrf in enumerate(lrf_types):\n",
    "                for j, testname in enumerate(testnames):\n",
    "                    hists[i, j] = df_desc[(df_desc['testname'] == testname) & (df_desc['lrf'] == lrf)][p].values[0]     \n",
    "            show_bar_plots(hists, testnames, lrf_types, empty=0.5, ticks_rotation=ticks_rotation, ylabel=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba407b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('data/debug/test_results.csv')\n",
    "# df['testname'] = df['testname'] + '_' + df['voxel_size'].astype(str)\n",
    "# df['pcc'] = df['correct_correspondences'] / df['correspondences']\n",
    "# df = df[(df['descriptor'] != 'fpfh') & (df['version'] == '03')]\n",
    "# df['lrf'] = df['lrf'].fillna('default')\n",
    "\n",
    "# parameters = ['pcc']\n",
    "# for pname in parameters:\n",
    "#     d = {desc + t: p for desc, t, p in df[df['lrf'] == 'default'][['descriptor', 'testname', pname]].values}\n",
    "#     df['default'] = (df['descriptor'] + df['testname']).apply(lambda t: d[t])\n",
    "#     df['relative_' + pname] = df[pname] / df['default']\n",
    "# analyze_lrfs(df, ['relative_' + pname for pname in parameters] + ['correct_correspondences'], ticks_rotation='vertical')\n",
    "# df = df[['version', 'testname', 'descriptor', 'lrf', 'pcc', 'correspondences', 'correct_correspondences', 'inliers', 'pcd_err', 't_err', 'r_err']]\n",
    "# display_colored(df.sort_values(['testname', 'descriptor']), columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289e504e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('data/debug/test_results_office.csv')\n",
    "# df['testname'] = df['testname'] + '_' + df['voxel_size'].astype(str)\n",
    "# df['pcc'] = df['correct_correspondences'] / df['correspondences']\n",
    "# df = df[df['descriptor'] != 'fpfh']\n",
    "# df['lrf'] = df['lrf'].fillna('default')\n",
    "\n",
    "# parameters = ['pcc']\n",
    "# for pname in parameters:\n",
    "#     d = {desc + t: p for desc, t, p in df[df['lrf'] == 'default'][['descriptor', 'testname', pname]].values}\n",
    "#     df['default'] = (df['descriptor'] + df['testname']).apply(lambda t: d[t])\n",
    "#     df['relative_' + pname] = df[pname] / df['default']\n",
    "# analyze_lrfs(df, ['relative_' + pname for pname in parameters] + ['correct_correspondences'], ticks_rotation='vertical')\n",
    "# df = df[['version', 'testname', 'descriptor', 'lrf', 'pcc', 'correspondences', 'correct_correspondences', 'inliers', 'pcd_err', 't_err', 'r_err']]\n",
    "# display_colored(df.sort_values(['testname', 'descriptor']), columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eeabd27",
   "metadata": {},
   "source": [
    "### FPFH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16a6b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('data/debug/fpfh_results_02.csv')\n",
    "# df['pcc'] = df['correct_correspondences'] / df['correspondences']\n",
    "# df_bun = df[df['testname'] == \"bun000_bun045\"][columns]\n",
    "# df_hokuyo = df[df['testname'] == 'Hokuyo_4_Hokuyo_8'][columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f1a032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_colored(df_bun.sort_values('pcd_err'), columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38264ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_colored(df_hokuyo.sort_values('pcd_err'),columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34afccba",
   "metadata": {},
   "source": [
    "### SHOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697ad70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('data/debug/shot_results_02.csv')\n",
    "# df['pcc'] = df['correct_correspondences'] / df['correspondences']\n",
    "# df_bun = df[df['testname'] == \"bun000_bun045\"][columns]\n",
    "# df_hokuyo = df[df['testname'] == 'Hokuyo_4_Hokuyo_8'][columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11874bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_colored(df_bun.sort_values('pcd_err'), columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f937f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_colored(df_hokuyo.sort_values('pcd_err'), columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c35574c",
   "metadata": {},
   "source": [
    "### RoPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10c9b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('data/debug/rops_results_02.csv')\n",
    "# df['pcc'] = df['correct_correspondences'] / df['correspondences']\n",
    "# df_bun = df[df['testname'] == \"bun000_bun045\"][columns]\n",
    "# df_hokuyo = df[df['testname'] == 'Hokuyo_4_Hokuyo_8'][columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365b9c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_colored(df_bun.sort_values('pcd_err'), columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d147c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_colored(df_hokuyo.sort_values('pcd_err'), columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44713bfe",
   "metadata": {},
   "source": [
    "### With normals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a215f22b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def with_normals(testname):\n",
    "    df = pd.read_csv('data/debug/test_results.csv')\n",
    "    df['pcc'] = df['correct_correspondences'] / df['correspondences']\n",
    "    df = df[df['testname'] == testname][columns]\n",
    "    df.loc[df['use_normals'] == 1, 'version'] = '02_normals'\n",
    "    df = df[df['voxel_size'] == 0.05]\n",
    "    df = df[['version', 'testname', 'descriptor','pcc', 'use_normals', 'normal_diff', 'normal_radius_coef', 'correct_correspondences', 'correspondences', 'correct_inliers', 'inliers']]\n",
    "    df = df.sort_values(by=['descriptor', 'normal_radius_coef', 'use_normals'])\n",
    "    display_colored(df, columns)\n",
    "    plot_line_graph(df, 'normal_radius_coef', 'correct_correspondences', ['02', '02_surface', '02_normals'], descriptors=['shot'])\n",
    "    plot_line_graph(df, 'normal_radius_coef', 'correct_correspondences', ['02', '02_surface', '02_normals'], descriptors=['fpfh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb779a5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# with_normals('kig_058_56_overlap_kig_013_12_overlap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4926be",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# with_normals('kig_077_75_kig_076_74')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ddb66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_difference(testname, pcd_type):\n",
    "    plt.rcParams[\"figure.figsize\"] = (8, 6)\n",
    "    df = pd.read_csv(f'data/debug/{testname}_normal_difference_{pcd_type}.csv')\n",
    "    df = df.drop_duplicates()\n",
    "    df_columns = [c for c in df.columns if c not in ['smoothing']]\n",
    "    show_confusion_matrix(df[df_columns], labels1=df_columns, labels2=df['smoothing'], vmax=0.35)\n",
    "    plt.rcParams[\"figure.figsize\"] = (8, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bff389",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# normal_difference('kig_058_56_overlap_kig_013_12_overlap', 'src')\n",
    "# normal_difference('kig_058_56_overlap_kig_013_12_overlap', 'tgt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c22180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal_difference('kig_077_75_kig_076_74', 'src')\n",
    "# normal_difference('kig_077_75_kig_076_74', 'tgt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83a935b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prc(paths: List[str], legends: List[str], thrs: List[float], reverse=False):\n",
    "    figs, axes = plt.subplots(nrows=1, ncols=4, figsize=(20,5))\n",
    "    for legend, path in zip(legends, paths):\n",
    "        df = pd.read_csv(path)\n",
    "        if reverse:\n",
    "            df['distance'] = 1.0 - df['distance']\n",
    "        precision = []\n",
    "        recall = []\n",
    "        f1 = []\n",
    "        for thr in thrs:\n",
    "            tp = len(df[(df['is_correct']) & (df['distance'] <= thr)])\n",
    "            fp = len(df[(~df['is_correct']) & (df['distance'] <= thr)])\n",
    "            fn = len(df[(df['is_correct']) & (df['distance'] > thr)])\n",
    "            recall.append(tp / (tp + fn))\n",
    "            if tp == 0:\n",
    "                precision.append(0.0)\n",
    "                f1.append(0.0)\n",
    "            else:\n",
    "                precision.append(tp / (fp + tp))\n",
    "                f1.append(2 * precision[-1] * recall[-1] / (precision[-1] + recall[-1]))\n",
    "            for ax in axes[:2]:\n",
    "                ax.axvline(x=thr, color='gray', linestyle='-.', alpha=0.1, linewidth=0.5)\n",
    "        axes[0].plot(thrs, precision, label=legend)\n",
    "        axes[1].plot(thrs, recall, label=legend)\n",
    "        axes[2].plot(recall, precision, label=legend)\n",
    "        axes[3].plot(thrs, f1, label=legend)\n",
    "    axes[0].set_xlabel('threshold')\n",
    "    axes[1].set_xlabel('threshold')\n",
    "    axes[2].set_xlabel('recall')\n",
    "    axes[3].set_xlabel('threshold')\n",
    "    axes[0].set_ylabel('precision')\n",
    "    axes[1].set_ylabel('recall')\n",
    "    axes[2].set_ylabel('precision')\n",
    "    axes[3].set_ylabel('f1 score')\n",
    "    axes[0].legend()\n",
    "    axes[1].legend()\n",
    "    axes[2].legend()\n",
    "    axes[3].legend()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a35537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths = ['data/debug/Hokuyo_4_Hokuyo_8_correspondences_debug_600_fpfh_flann_4_10_default_correspondences_ratio_1_05_prc.csv',\n",
    "#          'data/debug/Hokuyo_4_Hokuyo_8_correspondences_debug_600_shot_flann_4_10_default_correspondences_ratio_1_05_prc.csv',\n",
    "#          'data/debug/kig_058_56_kig_013_12_correspondences_debug_500_fpfh_bf_4_15_default_correspondences_ratio_1_05_prc.csv',\n",
    "#          'data/debug/kig_058_56_kig_013_12_correspondences_debug_500_shot_bf_4_15_default_correspondences_ratio_1_05_prc.csv']\n",
    "# names = ['Hokuyo_fpfh', 'Hokuyo_shot', 'kig_fpfh', 'kig_shot']\n",
    "# build_prc(paths, names, thrs=[0.8, 0.825, 0.85, 0.875, 0.9, 0.925, 0.95, 0.975, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6aad344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths = ['data/debug/bun000_bun045_correspondences_debug_8_fpfh_flann_4_10_default_correspondences_cluster_1_05_prc.csv']\n",
    "# names = ['bun_fpfh']\n",
    "# build_prc(paths, names, thrs=np.arange(12) / 12 * 0.4 + 0.6, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4611c47c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# paths = ['data/debug/kig_023_22_kig_024_23_correspondences_debug_500_shot_bf_3_15_default_correspondences_ratio_1_06.csv',\n",
    "#          'data/debug/kig_023_22_kig_024_23_correspondences_debug_500_shot_bf_3_15_default_correspondences_cluster_1_06.csv']\n",
    "# names = ['24_ratio_shot', '24_cluster_shot']\n",
    "# build_prc(paths, names, thrs=np.arange(1, 21) / 20 * 1.0 + 0.0)\n",
    "# paths = ['data/debug/kig_096_94_kig_094_92_correspondences_debug_500_shot_bf_3_15_default_correspondences_ratio_1_06.csv',\n",
    "#          'data/debug/kig_096_94_kig_094_92_correspondences_debug_500_shot_bf_3_15_default_correspondences_cluster_1_06.csv']\n",
    "# names = ['96_ratio_shot', '96_cluster_shot']\n",
    "# build_prc(paths, names, thrs=np.arange(1, 21) / 20 * 1.0 + 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4499feee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths = ['data/debug/kig_058_56_kig_013_12_correspondences_debug_500_fpfh_bf_4_15_default_correspondences_cluster_1_05_prc.csv',\n",
    "#          'data/debug/kig_058_56_kig_013_12_correspondences_debug_500_shot_bf_4_15_default_correspondences_cluster_1_05_prc.csv']\n",
    "# names = ['kig_fpfh', 'kig_shot']\n",
    "# build_prc(paths, names, thrs=np.arange(20) / 20 * 0.8 + 0.2, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be29ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths = ['data/debug/Hokuyo_4_Hokuyo_8_correspondences_debug_600_fpfh_flann_4_10_default_correspondences_cluster_2_05_prc.csv',\n",
    "#          'data/debug/Hokuyo_4_Hokuyo_8_correspondences_debug_600_shot_flann_4_10_default_correspondences_cluster_2_05_prc.csv']\n",
    "# names = ['Hokuyo_fpfh', 'Hokuyo_shot']\n",
    "# build_prc(paths, names, thrs=np.arange(20) / 20 * 0.8 + 0.2)\n",
    "# paths = ['data/debug/kig_058_56_kig_013_12_correspondences_debug_500_fpfh_bf_4_15_default_correspondences_cluster_2_05_prc.csv',\n",
    "#          'data/debug/kig_058_56_kig_013_12_correspondences_debug_500_shot_bf_4_15_default_correspondences_cluster_2_05_prc.csv']\n",
    "# names = ['kig_fpfh', 'kig_shot']\n",
    "# build_prc(paths, names, thrs=np.arange(20) / 20 * 0.8 + 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fded81f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths = ['data/debug/Hokuyo_4_Hokuyo_8_correspondences_debug_600_fpfh_flann_4_10_default_correspondences_cluster_1_05_prc.csv',\n",
    "#          'data/debug/Hokuyo_4_Hokuyo_8_correspondences_debug_600_shot_flann_4_10_default_correspondences_cluster_1_05_prc.csv',\n",
    "#          'data/debug/kig_058_56_kig_013_12_correspondences_debug_500_fpfh_bf_4_15_default_correspondences_cluster_1_05_prc.csv',\n",
    "#          'data/debug/kig_058_56_kig_013_12_correspondences_debug_500_shot_bf_4_15_default_correspondences_cluster_1_05_prc.csv']\n",
    "# names = ['Hokuyo_fpfh', 'Hokuyo_shot', 'kig_fpfh', 'kig_shot']\n",
    "# build_prc(paths, names, thrs=np.arange(20) / 20 * 0.8 + 0.2, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61371fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths = ['data/debug/Hokuyo_4_Hokuyo_8_correspondences_debug_600_fpfh_flann_4_10_default_correspondences_cluster_2_05_prc.csv',\n",
    "#          'data/debug/Hokuyo_4_Hokuyo_8_correspondences_debug_600_shot_flann_4_10_default_correspondences_cluster_2_05_prc.csv',\n",
    "#          'data/debug/kig_058_56_kig_013_12_correspondences_debug_500_fpfh_bf_4_15_default_correspondences_cluster_2_05_prc.csv',\n",
    "#          'data/debug/kig_058_56_kig_013_12_correspondences_debug_500_shot_bf_4_15_default_correspondences_cluster_2_05_prc.csv']\n",
    "# names = ['Hokuyo_fpfh', 'Hokuyo_shot', 'kig_fpfh', 'kig_shot']\n",
    "# build_prc(paths, names, thrs=np.arange(20) / 20 * 0.8 + 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e820af",
   "metadata": {},
   "source": [
    "### Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bce0706",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import matplotlib.colors as mcolors\n",
    "\n",
    "# PATH = os.path.join('data', 'debug')\n",
    "# COLORS = list(mcolors.BASE_COLORS.keys())\n",
    "\n",
    "# def analyze_weights(testnames, parameters):\n",
    "#     inliers, inliers_gt, curvatures = [], [], []\n",
    "#     for i, (testname, ps) in enumerate(zip(testnames, parameters)):\n",
    "#         inliers.append(pd.read_csv(os.path.join(PATH, testname + '_inliers_' + ps + '.csv')).values.flatten())\n",
    "#         inliers_gt.append(pd.read_csv(os.path.join(PATH, testname + '_inliers_gt_' + ps + '.csv')).values.flatten())\n",
    "#         curvatures.append(pd.read_csv(os.path.join(PATH, testname + '_curvatures_' + ps + '.csv')))\n",
    "\n",
    "#         count_nan = np.count_nonzero(curvatures[i]['k1'].isna())\n",
    "#         print(f'Curvatures contain {count_nan} NaNs')\n",
    "#         curvatures[i] = curvatures[i].fillna(0)\n",
    "#         curvatures[i]['kmax'] = np.maximum(curvatures[i]['k1'].values, curvatures[i]['k2'].values)\n",
    "\n",
    "#     k = len(testnames)\n",
    "#     fig, axes = plt.subplots(1, k, figsize=(k * 6, 4), squeeze=False)\n",
    "    \n",
    "#     for i in range(k):\n",
    "#         xs = np.arange((len(curvatures[i])))\n",
    "#         axes[0][i].plot(xs, np.sort(curvatures[i]['kmax'].values), color=COLORS[i % len(COLORS)])\n",
    "#         axes[0][i].set_title('All curvatures [%s]' % testnames[i])\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "#     fig, axes = plt.subplots(1, k, figsize=(k * 6, 4), squeeze=False)\n",
    "#     q = 0.8\n",
    "    \n",
    "#     exponential = []\n",
    "#     log_curvedness = []\n",
    "#     for i in range(k):\n",
    "#         xs = np.arange((len(curvatures[i])))\n",
    "#         Lambda = np.log(1.05) * np.quantile(curvatures[i]['kmax'].values, q)\n",
    "#         exponential.append(np.exp(-Lambda / curvatures[i]['kmax']))\n",
    "#         log_curvedness.append(np.log(1 + np.sqrt((curvatures[i]['k1'].values ** 2 + curvatures[i]['k2'].values ** 2) / 2.0)))\n",
    "        \n",
    "#         count_nonzero_exponential = np.count_nonzero(exponential[i] > 1e-3)\n",
    "#         count_nonzero_log_curvedness = np.count_nonzero(log_curvedness[i] > 1e-3)\n",
    "\n",
    "#         print(f'[{testnames[i]}] exponential weights: {count_nonzero_exponential}/{len(exponential[i])}')\n",
    "#         print(f'[{testnames[i]}] log curvedness weights: {count_nonzero_log_curvedness}/{len(log_curvedness[i])}')\n",
    "#         axes[0][i].plot(xs, np.sort(exponential[i]), label='exponential', color=COLORS[i % len(COLORS)])\n",
    "#         axes[0][i].plot(xs, np.sort(log_curvedness[i]), label='log curvedness', color=COLORS[(i + 4) % len(COLORS)])\n",
    "#         axes[0][i].set_title('All weights [%s]' % testnames[i])\n",
    "#         axes[0][i].legend()\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "#     fig, (axes0, axes1) = plt.subplots(2, k, figsize=(k * 6, 2 * 4), squeeze=False)\n",
    "\n",
    "#     for i in range(k):\n",
    "#         axes0[i].plot(np.arange(len(inliers[i])), np.sort(exponential[i][inliers[i]]), label='exponential', color=COLORS[i % len(COLORS)])\n",
    "#         axes1[i].plot(np.arange(len(inliers_gt[i])), np.sort(exponential[i][inliers_gt[i]]), label='exponential', color=COLORS[i % len(COLORS)])\n",
    "\n",
    "#         axes0[i].plot(np.arange(len(inliers[i])), np.sort(log_curvedness[i][inliers[i]]), label='log curvedness', color=COLORS[(i + 4) % len(COLORS)])\n",
    "#         axes1[i].plot(np.arange(len(inliers_gt[i])), np.sort(log_curvedness[i][inliers_gt[i]]), label='log curvedness', color=COLORS[(i + 4) % len(COLORS)])\n",
    "        \n",
    "#         axes0[i].set_title('Weights of incorrect [%s]' % testnames[i])\n",
    "#         axes1[i].set_title('Weights of correct [%s]' % testnames[i])\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "#     fig, axes = plt.subplots(1, k + 1, figsize=((k + 1) * 6, 4))\n",
    "    \n",
    "#     for i in range(k):\n",
    "#         incorrect_c = len(inliers[i]) / len(curvatures[i])\n",
    "#         correct_c = len(inliers_gt[i]) / len(curvatures[i])\n",
    "\n",
    "#         incorrect_exponential = exponential[i][inliers[i]].sum() / exponential[i].sum()\n",
    "#         correct_exponential = exponential[i][inliers_gt[i]].sum() / exponential[i].sum()\n",
    "\n",
    "#         incorrect_log_curvedness = log_curvedness[i][inliers[i]].sum() / log_curvedness[i].sum()\n",
    "#         correct_log_curvedness = log_curvedness[i][inliers_gt[i]].sum() / log_curvedness[i].sum()\n",
    "        \n",
    "#         print('[%s, count]          incorrect / correct: %.5f / %.5f' % (testnames[i], incorrect_c, correct_c))\n",
    "#         print('[%s, exponential]    incorrect / correct: %.5f / %.5f' % (testnames[i], incorrect_exponential, correct_exponential))\n",
    "#         print('[%s, log_curvedness] incorrect / correct: %.5f / %.5f' % (testnames[i], incorrect_log_curvedness, correct_log_curvedness))\n",
    "#         print()\n",
    "        \n",
    "#         quantile = np.quantile(curvatures[i]['kmax'].values, q)\n",
    "#         ms = 1.0 + np.arange(40) / 40 * 2.0\n",
    "#         correct, incorrect = [], []\n",
    "#         for m in ms:\n",
    "#             ws = np.exp(-np.log(m) * quantile / curvatures[i]['kmax'])\n",
    "#             incorrect.append(ws[inliers[i]].sum() / ws.sum())\n",
    "#             correct.append(ws[inliers_gt[i]].sum() / ws.sum())\n",
    "#             axes[i + 1].axvline(x=m, color='gray', linestyle='-.', alpha=0.1, linewidth=0.5)\n",
    "#         axes[0].plot(ms, np.array(correct) / np.array(incorrect), label=testnames[i], color=COLORS[i % len(COLORS)])\n",
    "#         axes[i + 1].plot(ms, np.array(correct) / np.array(incorrect), color=COLORS[i % len(COLORS)])\n",
    "#         axes[i + 1].set_title('Correct / incorrect ratio [%s]' % testnames[i])\n",
    "    \n",
    "#     axes[0].set_title('Correct / incorrect ratio')\n",
    "#     axes[0].legend()\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# testname = [\n",
    "#     'kig_016_15_kig_014_13',\n",
    "#     'kig_022_21_kig_023_22',\n",
    "#     'kig_023_22_kig_024_23',\n",
    "#     'kig_061_59_kig_044_43',\n",
    "#     'kig_097_95_kig_095_93'\n",
    "# ]\n",
    "# parameters = [\n",
    "#     '200_shot_bf_4_15_default_closest_point_cluster_1_log_curvedness_06',\n",
    "#     '500_shot_bf_3_15_default_correspondences_cluster_1_log_curvedness_06',\n",
    "#     '500_shot_bf_3_15_default_correspondences_cluster_1_log_curvedness_06',\n",
    "#     '500_shot_bf_3_15_default_correspondences_cluster_1_log_curvedness_06',\n",
    "#     '500_shot_bf_3_15_default_correspondences_cluster_1_log_curvedness_06'\n",
    "# ]\n",
    "# analyze_weights(testname, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945cdfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('data/debug/weights/test_metrics.csv')\n",
    "# df = df[df['testname'].apply(lambda s: not s.startswith('bun'))]\n",
    "# df['weights'] = df['testname'].apply(lambda s: s[s.rfind('1_') + 2: s.rfind('_06')])\n",
    "# df['testname'] = df['testname'].apply(lambda s: s[: s.find('metric') -1 ])\n",
    "# df['ratio'] = df['metric_icp'] / df['metric_icp_gt']\n",
    "# metric_columns = ['metric_corr', 'metric_corr_gt', 'metric_icp', 'metric_icp_gt', 'ratio']\n",
    "# df = df[['testname', 'weights'] + metric_columns]\n",
    "# df = df[df['weights'] == 'constant']\n",
    "# df['metric_prod'] = df['metric_corr'] * df['metric_icp']\n",
    "# df['metric_prod_gt'] = df['metric_corr_gt'] * df['metric_icp_gt']\n",
    "# metric_columns = ['metric_corr', 'metric_corr_gt', 'metric_icp', 'metric_icp_gt', 'ratio', 'metric_prod', 'metric_prod_gt']\n",
    "# df = df.sort_values(['testname', 'weights'])\n",
    "# display_colored(df, metric_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093db556",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(t: Tuple) -> str:\n",
    "    if len(t) == 1:\n",
    "        return t[0]\n",
    "    return '(' + ', '.join() + ')'\n",
    "    \n",
    "    \n",
    "def analyze_by(df, by: str, methods: List[str], analyzed_parameters: List[Union[str, Tuple]], descriptors=['shot', 'rops'],  ticks_rotation='horizontal', horizontal=False, y_labels=None, x_label=None):\n",
    "    for desc in descriptors:\n",
    "        df_desc = df[df['descriptor'] == desc]\n",
    "        testnames = list(sorted(reduce(np.intersect1d, [df_desc[df_desc[by] == method]['testname'].values for method in methods])))\n",
    "        df_desc = df_desc[df_desc['testname'].isin(testnames)]\n",
    "        df_desc = df_desc.sort_values('testname')\n",
    "        n, m = len(methods), len(testnames)\n",
    "        if m == 0:\n",
    "            continue\n",
    "        for k, ps in enumerate(analyzed_parameters):\n",
    "            if type(ps) is not tuple:\n",
    "                ps = (ps,)\n",
    "            hists = np.zeros((len(ps), n, m))\n",
    "            for l, p in enumerate(ps):\n",
    "                for i, method in enumerate(methods):\n",
    "                    for j, testname in enumerate(testnames):\n",
    "                        hists[l, i, j] = df_desc[(df_desc['testname'] == testname) & (df_desc[by] == method)][p].values[0]  \n",
    "            y_label= get_label(ps) if y_labels is None else y_labels[k]\n",
    "            show_bar_plots(hists, testnames, methods, empty=0.5, ticks_rotation=ticks_rotation, ylabel=y_label, xlabel=x_label, horizontal=horizontal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844644d3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('data/debug/test_results_thesis.csv')\n",
    "# df = df[((df['version'] == 7) & (df['matching'] == 'lr')) |\n",
    "#         ((df['version'] == 8) & (df['matching'] == 'cluster') & (df['metric'] == 'combination') & (df['lrf'] == 'default')) |\n",
    "#         ((df['version'] == 8) & (df['matching'] == 'cluster') & (df['metric'] == 'combination') & (df['lrf'] == 'gravity')) ]\n",
    "# df['type'] = 'симметричная проверка'\n",
    "# df['type'] = df['type'].where(df['matching'] != 'cluster', 'фильтрация')\n",
    "# df['type'] = df['type'].where(df['lrf'] != 'gravity', 'фильтрация + гравитация')\n",
    "# df['testname'] = df['testname'].apply(lambda name: name[5:7] + '-' + name[16:18])\n",
    "# df['pcc'] = df['correct_correspondences'] / df['correspondences']\n",
    "# analyze_by(df, by='type', methods=['симметричная проверка', 'фильтрация', 'фильтрация + гравитация'], analyzed_parameters=['pcc', 'correspondences', 'correct_correspondences'], y_labels=['Процент верных соответствий', 'Количество соответствий', 'Количество верных соответствий'], x_label=\"Пары облаков точек\", descriptors=['shot'])\n",
    "# display(df[df['testname'] == '62-46'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e44c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('data/test_measurements.csv')\n",
    "# df['mae'] = df['mae'] / np.pi * 180\n",
    "# df['sae'] = df['sae'] / np.pi * 180\n",
    "# df['success_rate'] = 100 * df['success_rate']\n",
    "# df['mte'] = 1000 * df['mte']\n",
    "# df['ste'] = 1000 * df['ste']\n",
    "# df['mrmse'] = 1000 * df['mrmse']\n",
    "# df['srmse'] = 1000 * df['srmse']\n",
    "# df['type'] = 'none'\n",
    "# df['type'] = df['type'].where(df['testname'].apply(lambda s: 'cluster' not in s), 'cluster')\n",
    "# df['type'] = df['type'].where(df['testname'].apply(lambda s: 'combination' not in s), 'metric')\n",
    "# df['type'] = df['type'].where(df['testname'].apply(lambda s: 'gravity' not in s), 'gravity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae14c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for t in ['none', 'cluster', 'metric']:\n",
    "#     for dataset in ['office', 'arch', 'trees']:\n",
    "#         df_p = df[df['testname'].apply(lambda s: s.startswith(dataset))]\n",
    "#         df_p = df_p[(df_p['type'] == t)]\n",
    "#         print(dataset, t, len(df_p), end=' ')\n",
    "#         print('%.0f' % df_p['success_rate'].mean(), end=' & ')\n",
    "#         df_p = df_p[(df_p['type'] == t) & (df_p['success_rate']!= 0)]\n",
    "#         print('%.0f $\\\\pm$ %.0f' % (df_p['mte'].mean(), df_p['ste'].mean()), end=' & ')\n",
    "#         print('%.2f $\\\\pm$ %.2f' % (df_p['mae'].mean(), df_p['sae'].mean()), end=' & ')\n",
    "#         print('%.0f $\\\\pm$ %.0f' % (df_p['mrmse'].mean(), df_p['srmse'].mean()), end=' \\\\\\\\')\n",
    "#         print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f897389d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('data/debug/test_results_thesis.csv')\n",
    "# df['pcc'] = df['correct_correspondences'] / df['correspondences']\n",
    "# df['testname'] = df['testname'].apply(lambda name: name[5:7] + '-' + name[16:18])\n",
    "# df['type'] = 'initial'\n",
    "# df['type'] = df['type'].where(~((df['matching'] == 'cluster') & (df['lrf'] == 'default')), 'cluster')\n",
    "# df['type'] = df['type'].where(~((df['matching'] == 'cluster') & (df['lrf'] == 'gravity')), 'cluster + gravity')\n",
    "# df = df[~((df['metric'] == 'combination') & (df['matching'] == 'cluster') & (df['lrf'] == 'default'))]\n",
    "# df = df[df['ctf'] == 0]\n",
    "# analyze_by(df, by='type', methods=['initial', 'cluster', 'cluster + gravity'], analyzed_parameters=['pcc', 'correct_correspondences', 'pcd_err'], descriptors=['shot'])\n",
    "# df = df[['testname', 'descriptor', 'lrf', 'metric', 'matching', 'ctf', 'voxel_size', 'overlap_rmse', 'correspondences', 'correct_correspondences', 'pcc', 'inliers', 'correct_inliers']]\n",
    "# display_colored(df.sort_values(['testname', 'lrf', 'matching']), columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dc3576",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/debug/test_results.csv')\n",
    "df = df.fillna('default')\n",
    "df['type'] = ''\n",
    "df['type'] = df['type'].where(~((df['alignment'] == 'default') & (df['voxel_size'] == 0.04) & (df['matching'] == 'cluster') & (df['metric'] == 'combination') & (df['lrf'] == 'gravity')), 'baseline')\n",
    "df['type'] = df['type'].where(df['alignment'] != 'gror', 'gror')\n",
    "df['type'] = df['type'].where(~((df['alignment'] == 'default') & (df['keypoint'] == 'any') & (df['voxel_size'] == 0.1) & (df['matching'] == 'lr') & (df['metric'] == 'correspondences') & (df['lrf'] == 'default')), 'no keypoints')\n",
    "df['type'] = df['type'].where(~((df['alignment'] == 'default') & (df['keypoint'] == 'iss') & (df['voxel_size'] == 0.1) & (df['matching'] == 'lr') & (df['metric'] == 'correspondences') & (df['lrf'] == 'default')), 'keypoints')\n",
    "df = df[df['type'] != '']\n",
    "for column in ['t_err', 'r_err', 'overlap_rmse']:\n",
    "    df[column] = pd.to_numeric(df[column])\n",
    "df = df.drop_duplicates(subset=['testname', 'type'])\n",
    "df['pcc'] = df['correct_correspondences'] / df['correspondences']\n",
    "df['testname'] = df['testname'].apply(lambda name: name[5:7] + '-' + name[16:18])\n",
    "# analyze_by(df, by='type', methods=['baseline', 'gror', 'keypoints', 'no keypoints'], analyzed_parameters=['t_err', 'r_err', 'overlap_rmse'], descriptors=['shot'])\n",
    "df = df[['version', 'descriptor','testname', 'type', 'r_err','t_err','pcc', 'correct_correspondences', 'correspondences', 'inliers', 'correct_inliers','overlap_rmse']]\n",
    "display_colored(df.sort_values(['testname', 'type']), columns, cmap='YlGnBu', qmin=0.2, qmax=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888d2714",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_features(path_src, path_tgt):\n",
    "    features_src = pd.read_csv(path_src)\n",
    "    features_tgt = pd.read_csv(path_tgt)\n",
    "    features_diff = features_src - features_tgt\n",
    "    f1_diff = features_diff['f1']\n",
    "    f2_diff = features_diff['f2']\n",
    "    f3_diff = features_diff['f3']\n",
    "    f4_diff = features_diff['f4']\n",
    "\n",
    "    fs1 = f1_diff.values\n",
    "    f1_std = np.std(fs1)\n",
    "    print(f'f1: {np.count_nonzero(fs1 > f1_std) / len(fs1)}')\n",
    "\n",
    "    fs2 = f2_diff.values\n",
    "    f2_std = np.std(fs2)\n",
    "    print(f'f2: {np.count_nonzero(fs2 > f2_std) / len(fs2)}')\n",
    "\n",
    "    fs3 = f3_diff.values\n",
    "    f3_std = np.std(fs3)\n",
    "    print(f'f3: {np.count_nonzero(fs3 > f3_std) / len(fs3)}')\n",
    "\n",
    "    plt.hist(f1_diff, bins='rice')\n",
    "    plt.show()\n",
    "\n",
    "    plt.hist(f2_diff, bins='rice')\n",
    "    plt.show()\n",
    "\n",
    "    plt.hist(f3_diff, bins='rice')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad764ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5994 - левый угол\n",
    "# 245 - верх спинки\n",
    "# 1565 - середина спинки\n",
    "# 5545 - нижний угол\n",
    "\n",
    "# point_ids = pd.read_csv('data/debug/kig_023_22_chair_kig_022_21_chair_ids_02.csv')\n",
    "# point_ids.set_index('id_src', drop=False, inplace=True)\n",
    "# point_ids_src = point_ids['id_src'].values\n",
    "# point_ids_tgt = point_ids['id_tgt'].values\n",
    "# ids_src = np.array([5994, 245, 1565, 5545])\n",
    "# ids_tgt = np.array([point_ids[point_ids['id_src'] == id_src]['id_tgt'].values[0] for id_src in ids_src])\n",
    "# display(point_ids.loc[ids_src])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec2984e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze_descriptors(\"data/debug/kig_023_22_chair_kig_022_21_chair_histograms_src_02_shot.csv\",\n",
    "#                     \"data/debug/kig_023_22_chair_kig_022_21_chair_histograms_tgt_02_shot.csv\",\n",
    "#                     ids_src, ids_tgt,\n",
    "#                     descriptor_size=352,\n",
    "#                     confusion_matrix_fn=cosine_confusion_matrix,\n",
    "#                     descriptions=['left upper', 'upper', 'center', 'left bottom'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3746551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze_descriptors(\"data/debug/kig_023_22_chair_kig_022_21_chair_histograms_src_02.csv\",\n",
    "#                     \"data/debug/kig_023_22_chair_kig_022_21_chair_histograms_tgt_02.csv\",\n",
    "#                     ids_src, ids_tgt,\n",
    "#                     descriptor_size=33,\n",
    "#                     confusion_matrix_fn=min_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e24d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('test_results.csv')\n",
    "# df = df.fillna('')\n",
    "# df['pcc'] = df['correct_correspondences'] / df['correspondences']\n",
    "# df['overlapping'] = [df_overlapping.loc[testname[:testname.rfind('kig') - 1] + '.ply'][testname[testname.rfind('kig'):] + '.ply'] for testname in df['testname']]\n",
    "# df = df[df['overlapping'] > 0.35]\n",
    "# df = df[df['pcd_err'] > 0.05]\n",
    "# df = df[['testname', 'r_err', 't_err', 'pcd_err', 'pcc', 'helpful', 'correct_correspondences', 'correspondences', 'correct_inliers', 'overlapping']].sort_values('pcc')\n",
    "# df = df.sort_values('pcd_err')\n",
    "# display_colored(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab808bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/test_levels.csv')\n",
    "df = df.fillna('')\n",
    "df['source'] = df['testname'].apply(lambda s: (s if s[:3] == 'kig' else s[:s.find('_')]) + '.ply')\n",
    "df['target'] = df['testname'].apply(lambda s: (s if s[:3] == 'kig' else s[s.find('_') + 1:]) + '.ply')\n",
    "df = df[['source', 'target', 'testname', 'helpful', 'level']]\n",
    "display(df)\n",
    "df.to_csv('data/test_levels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e2f913",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['level'] == 2]\n",
    "display(df)\n",
    "print(np.min(df['overlapping']), np.max(df['overlapping']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bab3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# very difficult = 3, difficult = 2, middle = 1, easy = 0, no = -1\n",
    "\n",
    "# df = pd.read_csv('test_results.csv')\n",
    "# df = df.fillna('')\n",
    "# df['level'] = ''\n",
    "# df['level'] = df['level'].where(df['helpful'] == '', other=5) \n",
    "# df = df[['testname', 'helpful', 'level']]\n",
    "# df['level'] = df['level'].where(df['testname'] != 'kig_058_56_kig_013_12', other=2) \n",
    "# df['level'] = df['level'].where(df['testname'] != 'kig_090_88_kig_088_86', other=2) \n",
    "# df['level'] = df['level'].where(df['testname'] != 'kig_061_59_kig_044_43', other=2) \n",
    "# df['level'] = df['level'].where(df['testname'] != 'kig_091_89_kig_089_87', other=3)\n",
    "# df['level'] = df['level'].where(df['testname'] != 'kig_093_91_kig_092_90', other=2)\n",
    "# df['level'] = df['level'].where(df['testname'] != 'kig_044_43_kig_011_10', other=1)\n",
    "# df['level'] = df['level'].where(df['testname'] != 'kig_045_44_kig_040_39', other=2)\n",
    "# df['level'] = df['level'].where(df['testname'] != 'kig_089_87_kig_087_85', other=3)\n",
    "# df['level'] = df['level'].where(df['testname'] != 'kig_096_94_kig_094_92', other=2)\n",
    "# df['level'] = df['level'].where(df['testname'] != 'kig_097_95_kig_095_93', other=2)\n",
    "# df['level'] = df['level'].where(df['testname'] != 'kig_024_23_kig_023_22', other=2)\n",
    "# df['level'] = df['level'].where(df['testname'] != 'kig_051_50_kig_040_39', other=2)\n",
    "# df['level'] = df['level'].where(df['testname'] != 'kig_088_86_kig_079_77', other=-1)\n",
    "# df['level'] = df['level'].where(df['testname'] != 'kig_059_57_kig_048_47', other=3)\n",
    "# df['level'] = df['level'].where(df['testname'] != 'kig_087_85_kig_079_77', other=-1)\n",
    "# df['level'] = df['level'].where(df['testname'] != 'kig_040_39_kig_013_12', other=2)\n",
    "# df['level'] = df['level'].where(df['testname'] != 'kig_017_16_kig_015_14', other=-1)\n",
    "# df['level'] = df['level'].where(df['testname'] != 'kig_016_15_kig_014_13', other=2)\n",
    "# df['level'] = df['level'].where(df['testname'] != 'kig_062_60_kig_046_45', other=2)\n",
    "# df['level'] = df['level'].where(df['testname'] != 'kig_051_50_kig_011_10', other=3)\n",
    "# df['level'] = df['level'].where(df['testname'] != 'kig_096_94_kig_095_93', other=2)\n",
    "# df['level'] = df['level'].where(df['testname'] != 'kig_051_50_kig_024_23', other=2)\n",
    "# df['level'] = df['level'].where(df['testname'] != 'kig_095_93_kig_094_92', other=2)\n",
    "# df['level'] = df['level'].where(df['testname'] != 'kig_044_43_kig_039_38', other=2)\n",
    "# df['level'] = df['level'].where(df['testname'] != 'kig_092_90_kig_090_88', other=2)\n",
    "# df['level'] = df['level'].where(df['testname'] != 'kig_090_88_kig_089_87', other=2)\n",
    "# df['level'] = df['level'].where(df['testname'] != 'kig_097_95_kig_094_92', other=2)\n",
    "# df['level'] = df['level'].where(df['testname'] != 'kig_090_88_kig_089_87', other=1)\n",
    "# df['level'] = df['level'].where(df['testname'] != 'kig_046_45_kig_012_11', other=2)\n",
    "# df['level'] = df['level'].where(df['testname'] != 'kig_040_39_kig_011_10', other=1)\n",
    "# df['level'] = df['level'].where(df['testname'] != 'kig_089_87_kig_088_86', other=1)\n",
    "# df['level'] = df['level'].where(df['testname'] != 'kig_048_47_kig_045_44', other=1)\n",
    "# display(df)\n",
    "# df.to_csv('test_levels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965152d6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('test_results_kig.csv')\n",
    "# df['pcc'] = df['correct_correspondences'] / df['correspondences']\n",
    "# display(df[['testname', 'pcc', 'correct_correspondences', 'correspondences']].sort_values(by=['pcc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9c661d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('test_levels.csv')\n",
    "# df = df.fillna('')\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33d3f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# point_ids = pd.read_csv('data/debug/kig_058_56_window_kig_013_12_window_ids_500_fpfh_flann_02.csv')\n",
    "# point_ids['distance2'] = (point_ids['x_src'] - point_ids['x_tgt']) ** 2 + \\\n",
    "#                          (point_ids['y_src'] - point_ids['y_tgt']) ** 2 + \\\n",
    "#                          (point_ids['z_src'] - point_ids['z_tgt']) ** 2\n",
    "# point_ids = point_ids.sort_values(by=['id_src', 'distance2'])\n",
    "# point_ids.set_index('id_src', drop=False, inplace=True)\n",
    "# point_ids = point_ids[~point_ids.index.duplicated(keep='first')]\n",
    "# point_ids_src = point_ids['id_src'].values\n",
    "# point_ids_tgt = point_ids['id_tgt'].values\n",
    "# # all_ids_src = [70081, 69637, 55565, 97463, 141934, 133020, 402, 129162, 129173, 77361]\n",
    "# # ids_src = np.array(list(filter(lambda i: i in point_ids.index, all_ids_src)))\n",
    "# ids_src = [853, 8921, 5980, 6636, 4196]\n",
    "# ids_tgt = np.array([point_ids[point_ids['id_src'] == id_src]['id_tgt'].values[0] for id_src in ids_src])\n",
    "# display(point_ids.loc[ids_src])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b18b5ee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# analyze_descriptors(\"data/debug/kig_058_56_window_kig_013_12_window_histograms_src_500_fpfh_flann_02.csv\",\n",
    "#                     \"data/debug/kig_058_56_window_kig_013_12_window_histograms_tgt_500_fpfh_flann_02.csv\",\n",
    "#                     ids_src, ids_tgt,\n",
    "#                     descriptor_size=33,\n",
    "#                     confusion_matrix_fn=min_confusion_matrix,\n",
    "#                     descriptions=['верх', 'середина', 'край', 'подальше', 'далеко'],\n",
    "#                     vmin=0, vmax=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62b78bd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# analyze_descriptors(\"data/debug/kig_058_56_window_kig_013_12_window_histograms_src_500_rops_bf_02.csv\",\n",
    "#                     \"data/debug/kig_058_56_window_kig_013_12_window_histograms_tgt_500_rops_bf_02.csv\",\n",
    "#                     ids_src, ids_tgt,\n",
    "#                     descriptor_size=135,\n",
    "#                     confusion_matrix_fn=min_confusion_matrix,\n",
    "#                     descriptions=['верх', 'середина', 'край', 'подальше', 'далеко'],\n",
    "#                     vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac31279",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# analyze_descriptors(\"data/debug/kig_058_56_window_kig_013_12_window_histograms_src_500_shot_bf_02.csv\",\n",
    "#                     \"data/debug/kig_058_56_window_kig_013_12_window_histograms_tgt_500_shot_bf_02.csv\",\n",
    "#                     ids_src, ids_tgt,\n",
    "#                     descriptor_size=352,\n",
    "#                     confusion_matrix_fn=cosine_confusion_matrix,\n",
    "#                     descriptions=['верх', 'середина', 'край', 'подальше', 'далеко'],\n",
    "#                     vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b671d8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20, 20)\n",
    "\n",
    "df = pd.read_csv('data/kizhi/normals/downsampled_0.05/overlapping.csv', index_col='reading')\n",
    "show_confusion_matrix(df.values.astype(np.float64), labels1=df.index, labels2=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901f831d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd1 = 'kig_045_44.ply'\n",
    "pcd2 = 'kig_051_50.ply'\n",
    "df.index[(df.loc[pcd1] * df.loc[pcd2]).argsort()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b5d803",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
